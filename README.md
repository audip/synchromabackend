# Synchroma Backend [Best use of CapitalOne's Nessie API award, TAMUHack 2016]

Devpost: https://devpost.com/software/nullhands-ymta16

## Inspiration
Our inspiration comes from our own experiences as programmers, where we realized that it was sometimes difficult (and a productivity drain), to move our right hands between our keyboard and our mouse. We wondered whether there was any possibility of redesigning a new version of the mouse to work without the need to move our hand from the keyboard.

## What it does
nullHands utilizes a variety of measurements to provide users with an accurate mouse movement system. First, we utilize a gyroscope to grab the user's head movements, mapping that to the mouse movements on the screen. Then, we monitored the user's eyes, mapping the left and right eyes to the left and right respective mouse clicks.

## How we built it
We built this using iOS Swift 3, to monitor the gyroscope. We then used Python with sockets to run the backend, as well as to run the OpenCV and Mouse movement libraries

## Challenges we ran into
We did not have the hardware we needed, so we had to improvise with an iPhone, as well as a headband.

## Accomplishments that we're proud of
We are proud of managing to create a working prototype in under 24 hours.

## What we learned
We learned about sockets and direct communication between iOS and computer.

## What's next for nullHands
We are really passionate about nullHands, and think that this is a project that can definitely help a lot of people. Therefore, we plan on continuing to work on nullHands, improving and adding functionality so that we can one day release this as a product so that everyone can experience nullHands.
